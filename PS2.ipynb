{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "PS2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7bcefc05b16b41d5a2681c23b8412ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a9025830273b487482ff8117ebdce437",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6258dee1edc54e16980b35b9752cec3e",
              "IPY_MODEL_cc3dd99fe2524fca95c1f9e952901610",
              "IPY_MODEL_bd6ebbaecd3e445b9cfcee3c0219f5e0"
            ]
          }
        },
        "a9025830273b487482ff8117ebdce437": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6258dee1edc54e16980b35b9752cec3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5d23291304ec4886aa62676576123a8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e798172a3ebf4e9e89cabbcb8428bfda"
          }
        },
        "cc3dd99fe2524fca95c1f9e952901610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_258109e087b4446ea7ea4e30ac381b7f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d2bfdf4f59144d5a6b2199a63885fb2"
          }
        },
        "bd6ebbaecd3e445b9cfcee3c0219f5e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc802c3f96274dbc8ad3cade3ad7a094",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [00:00&lt;00:00, 29605935.04it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c47bf4dc305643bfb3fae2308698905c"
          }
        },
        "5d23291304ec4886aa62676576123a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e798172a3ebf4e9e89cabbcb8428bfda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "258109e087b4446ea7ea4e30ac381b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d2bfdf4f59144d5a6b2199a63885fb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc802c3f96274dbc8ad3cade3ad7a094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c47bf4dc305643bfb3fae2308698905c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5da00c72ac54321968b0fe6eb3e1129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c30c8f6ce0af4a7bad3414179da4b668",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a40405371c1243c386f2fe2d52cad49d",
              "IPY_MODEL_2a8d50556598470aaa087c5f9b34dd9c",
              "IPY_MODEL_64e35c730a3b422597ae4848e2ddff71"
            ]
          }
        },
        "c30c8f6ce0af4a7bad3414179da4b668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a40405371c1243c386f2fe2d52cad49d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b3acb3e6699d453885659f1fe899061d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec8418cd974f4ebb9657e029178f79d7"
          }
        },
        "2a8d50556598470aaa087c5f9b34dd9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d586b1c78b7048b5ac872c5006f54a88",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b6b66742e934a73b02857db2416bfeb"
          }
        },
        "64e35c730a3b422597ae4848e2ddff71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ae65a570342749fd9c214b7da34d882b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:00&lt;00:00, 730590.86it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2a3a724bd624ee597731c923dd3233c"
          }
        },
        "b3acb3e6699d453885659f1fe899061d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec8418cd974f4ebb9657e029178f79d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d586b1c78b7048b5ac872c5006f54a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b6b66742e934a73b02857db2416bfeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae65a570342749fd9c214b7da34d882b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2a3a724bd624ee597731c923dd3233c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45796f9a9c764953adf4764dccab477e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a8bd752e60cd44d89f990cc465e57492",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5de65ed503a344a9975f627e06299505",
              "IPY_MODEL_450b036e625e4aed9762d334b928f72e",
              "IPY_MODEL_200922c491d942b3b19b9014a92a8d60"
            ]
          }
        },
        "a8bd752e60cd44d89f990cc465e57492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5de65ed503a344a9975f627e06299505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ef0bb2458074316a6eb1ee344b11b2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20d66ba534044d22aff017d6d5ac646c"
          }
        },
        "450b036e625e4aed9762d334b928f72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1266e7c70bd54d1e9ca7349e1fcf106e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a5d06e952514fb88956e764a30112ab"
          }
        },
        "200922c491d942b3b19b9014a92a8d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e68c632202a448588c4c291880c660c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:00&lt;00:00, 5021143.07it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81f9053becec499fb9a2be9469f77e30"
          }
        },
        "6ef0bb2458074316a6eb1ee344b11b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20d66ba534044d22aff017d6d5ac646c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1266e7c70bd54d1e9ca7349e1fcf106e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a5d06e952514fb88956e764a30112ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e68c632202a448588c4c291880c660c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81f9053becec499fb9a2be9469f77e30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec3c2e9347fa4aa0bba412c6ad403750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_00409ed0a07a4fe6924c84993ef8bfc8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_125cea41bf654c95aafca4d995587e23",
              "IPY_MODEL_a288d3a02df7452284846ca077584e04",
              "IPY_MODEL_0ef89586ef4b4dcb9f54f6c2e6c0e60d"
            ]
          }
        },
        "00409ed0a07a4fe6924c84993ef8bfc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "125cea41bf654c95aafca4d995587e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7801f1c1edcf4204bee73e751f37a438",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e05454940af94fe3b98383564d1dab3f"
          }
        },
        "a288d3a02df7452284846ca077584e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aa4f0139bcd74091b7a5abad51830065",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c105e063f4b846c29f573fe752e5e6ae"
          }
        },
        "0ef89586ef4b4dcb9f54f6c2e6c0e60d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0bde497a17e14a6f994d54986a8e056c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 202841.56it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_102c2a1fa6e04a5eb9bfaeb70333656e"
          }
        },
        "7801f1c1edcf4204bee73e751f37a438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e05454940af94fe3b98383564d1dab3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa4f0139bcd74091b7a5abad51830065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c105e063f4b846c29f573fe752e5e6ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bde497a17e14a6f994d54986a8e056c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "102c2a1fa6e04a5eb9bfaeb70333656e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeMonet/TTIC31230/blob/main/PS2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3PKsz-1SH1U"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "For this assignment you will use PyTorch instead of EDF to implement and train neural networks. The experiments in this assignment will take a long time to run without a GPU, but you can run the notebook remotely on Google Colab and have access to GPUs for free -- in this case you don't have to worry about installing PyTorch as it is available by default in Google Colab's environment.\n",
        "\n",
        "In case you will be running the experiments in your own machine, you should install PyTorch -- there are multiple tutorials online and it is especially easy if you're using Anaconda. Check https://pytorch.org/tutorials/ for some PyTorch tutorials -- this assignment assumes that you know the basics like defining models with multiple modules and coding up functions to train models with PyTorch optimizers. To \n",
        "\n",
        "To use Google Colab, you should access https://colab.research.google.com/ and upload this notebook to your workspace. To use a GPU, go to Edit -> Notebook settings and select GPU as the accelerator.\n",
        "\n",
        "Unlike previous assignments, in this one you will have to do some writing instead of just coding. Try to keep your answers short and precise, and you are encouraged to write equations if needed (you can do that using markdown cells). You can also use code as part of your answers (like plotting and printing, etc). Blue text indicates questions or things that you should discuss/comment, and there will red \"ANSWER (BEGIN)\" and \"ANSWER (END)\" markdown cells to indicate that you should add cells with your writeup between these two. **Make sure not to redefine variables or functions in your writeup, which can change the behavior of the next cells.**\n",
        "\n",
        "Finally, you might have to do minor changes to the provided code due to differences in python/pytorch versions. You can post on piazza if there's a major, non-trivial change that you had to do (so other students can be aware of it and how to proceed), but for minor changes you should just apply them and keep working on the assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD0LkiPhSH1Z"
      },
      "source": [
        "import torch, math, copy\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_qmffSoSH1o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471,
          "referenced_widgets": [
            "7bcefc05b16b41d5a2681c23b8412ed4",
            "a9025830273b487482ff8117ebdce437",
            "6258dee1edc54e16980b35b9752cec3e",
            "cc3dd99fe2524fca95c1f9e952901610",
            "bd6ebbaecd3e445b9cfcee3c0219f5e0",
            "5d23291304ec4886aa62676576123a8c",
            "e798172a3ebf4e9e89cabbcb8428bfda",
            "258109e087b4446ea7ea4e30ac381b7f",
            "9d2bfdf4f59144d5a6b2199a63885fb2",
            "cc802c3f96274dbc8ad3cade3ad7a094",
            "c47bf4dc305643bfb3fae2308698905c",
            "f5da00c72ac54321968b0fe6eb3e1129",
            "c30c8f6ce0af4a7bad3414179da4b668",
            "a40405371c1243c386f2fe2d52cad49d",
            "2a8d50556598470aaa087c5f9b34dd9c",
            "64e35c730a3b422597ae4848e2ddff71",
            "b3acb3e6699d453885659f1fe899061d",
            "ec8418cd974f4ebb9657e029178f79d7",
            "d586b1c78b7048b5ac872c5006f54a88",
            "9b6b66742e934a73b02857db2416bfeb",
            "ae65a570342749fd9c214b7da34d882b",
            "c2a3a724bd624ee597731c923dd3233c",
            "45796f9a9c764953adf4764dccab477e",
            "a8bd752e60cd44d89f990cc465e57492",
            "5de65ed503a344a9975f627e06299505",
            "450b036e625e4aed9762d334b928f72e",
            "200922c491d942b3b19b9014a92a8d60",
            "6ef0bb2458074316a6eb1ee344b11b2c",
            "20d66ba534044d22aff017d6d5ac646c",
            "1266e7c70bd54d1e9ca7349e1fcf106e",
            "4a5d06e952514fb88956e764a30112ab",
            "e68c632202a448588c4c291880c660c1",
            "81f9053becec499fb9a2be9469f77e30",
            "ec3c2e9347fa4aa0bba412c6ad403750",
            "00409ed0a07a4fe6924c84993ef8bfc8",
            "125cea41bf654c95aafca4d995587e23",
            "a288d3a02df7452284846ca077584e04",
            "0ef89586ef4b4dcb9f54f6c2e6c0e60d",
            "7801f1c1edcf4204bee73e751f37a438",
            "e05454940af94fe3b98383564d1dab3f",
            "aa4f0139bcd74091b7a5abad51830065",
            "c105e063f4b846c29f573fe752e5e6ae",
            "0bde497a17e14a6f994d54986a8e056c",
            "102c2a1fa6e04a5eb9bfaeb70333656e"
          ]
        },
        "outputId": "36c51cda-746c-4717-b1b6-a170d63d7752"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "train_dataset = datasets.MNIST(\"data\", train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(\"data\", train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bcefc05b16b41d5a2681c23b8412ed4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5da00c72ac54321968b0fe6eb3e1129",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45796f9a9c764953adf4764dccab477e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec3c2e9347fa4aa0bba412c6ad403750",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIviUo83SH1o"
      },
      "source": [
        "Fill the missing code below. In both train_epoch and test, total_correct should be the total number of correctly classified samples, while total_samples should be the total number of samples that have been iterated over."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIHugdT9SH1o"
      },
      "source": [
        "def train(epochs, model, criterion, optimizer, train_loader, test_loader):\n",
        "    for epoch in range(epochs):\n",
        "        train_err = train_epoch(model, criterion, optimizer, train_loader)\n",
        "        test_err = test(model, test_loader)\n",
        "        print('Epoch {:03d}/{:03d}, Train Error {:.2f}% || Test Error {:.2f}%'.format(epoch, epochs, train_err*100, test_err*100))\n",
        "    return train_err, test_err\n",
        "    \n",
        "def train_epoch(model, criterion, optimizer, loader):\n",
        "    total_correct = 0.\n",
        "    total_samples = 0.\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        # insert code to feed the data to the model and collect its output\n",
        "        output = model(data)\n",
        "\n",
        "        # insert code to compute the loss from output and the true target\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # insert code to update total_correct and total_samples\n",
        "        # total_correct: total number of correctly classified samples\n",
        "        # total_samples: total number of samples seen so far\n",
        "        total_correct += torch.eq(torch.max(output, 1).indices, target).long().sum().item()\n",
        "\n",
        "\n",
        "\n",
        "        #output = output.detach().numpy()\n",
        "        #target = target.numpy()\n",
        "        #pred = np.argmax(output, axis=1)\n",
        "        #total_correct += (pred==target).astype(int).sum().item()\n",
        "        total_samples += data.size(0)\n",
        "\n",
        "\n",
        "        # insert code to update the parameters using optimizer\n",
        "        # be careful in this part as an incorrect implementation will affect\n",
        "        # all your experiments and have a significant impact on your grade!\n",
        "        # in particular, note that pytorch does --not-- automatically\n",
        "        # clear the parameter's gradients: check tutorials to see\n",
        "        # how this can be done with a single method call.\n",
        "        ...\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return 1 - total_correct/total_samples\n",
        "    \n",
        "def test(model, loader):\n",
        "    total_correct = 0.\n",
        "    total_samples = 0.\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(loader):\n",
        "            if torch.cuda.is_available():\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "\n",
        "            # insert code to feed the data to the model and collect its output\n",
        "            output = model(data)\n",
        "\n",
        "            # insert code to update total_correct and total_samples\n",
        "            # total_correct: total number of correctly classified samples\n",
        "            # total_samples: total number of samples seen so far\n",
        "            \n",
        "            total_correct += torch.eq(torch.max(output, 1).indices, target).long().sum().item()\n",
        "            #output = output.detach().numpy() # make numpy array, remove grad\n",
        "            #target = target.numpy()\n",
        "            #pred = np.argmax(output, axis=1) #find index of highest value\n",
        "            #total_correct += (pred==target).astype(int).sum().item()\n",
        "\n",
        "            total_samples += data.size(0)\n",
        "\n",
        "\n",
        "    return 1 - total_correct/total_samples"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cTYkX0GSH1p"
      },
      "source": [
        "### CNN with Tanh activations\n",
        "\n",
        "Next, you should implement a baseline model so you can check how increasing the number of layers can make a network considerably harder to train, given that no additional methods such as residual connections and normalization layers are adopted.\n",
        "\n",
        "Finish the implementation of CNNtanh below, carefully following the specifications:\n",
        "\n",
        "The model should have exactly 'k' many convolutional layers, followed by a linear (fully-connected) layer that actually outputs the logits for each of the 10 MNIST classes.\n",
        "\n",
        "The network should consist of 3 stages, each with k/3 many convolutional layers (you can assume k is divisible by 3). Each conv layer should have a 3x3 kernel, a stride of 1 and a padding of 1 pixel (such that the output of the convolution has the same height and width as its input).\n",
        "\n",
        "It should also have an average pooling layer at the end of each stage, with a 2x2 window (hence halving the spatial dimensions), and the number of channels should double from one stage to the other (starting with 4 in the first stage). Moreover, a Tanh activation should follow each convolution layer.\n",
        "\n",
        "When k=3, for example, the network should be:\n",
        "\n",
        "1. Stage 1 (1x28x28 input, 4x14x14 output):\n",
        "    1. Conv layer with 1 input channel and 4 output channels, 3x3 kernel, stride=padding=1\n",
        "    2. Tanh activation\n",
        "    3. Average Pool with 2x2 kernel and stride 2\n",
        "2. Stage 2 (4x14x14 input, 8x7x7 output):\n",
        "    1. Conv layer with 4 input channels and 8 output channels, 3x3 kernel, stride=padding=1\n",
        "    2. Tanh activation\n",
        "    3. Average Pool with 2x2 kernel and stride 2\n",
        "3. Stage 3 (8x7x7 input, 16x3x3 output):\n",
        "    1. Conv layer with 8 input channels and 16 output channels, 3x3 kernel, stride=padding=1\n",
        "    2. Tanh activation\n",
        "    3. Average Pool with 2x2 kernel and stride 2\n",
        "4. Fully-connected layer with 16 * 3 * 3=144 input dimension and 10 output dimension\n",
        "\n",
        "Note that the model should not have any activation after the fully-connected layer: the PyTorch loss module that will be adopted takes logits as input and not class probabilities.\n",
        "\n",
        "In contrast to the network exemplified above with k=3, when k=6 it should have two conv layers per stage instead of one (each one with a tanh activation following it).\n",
        "\n",
        "Lastly, do not change the code block with a for loop in the end of init: its purpose to randomly initialize the parameters of the conv layers by sampling from a Gaussian with zero mean and 0.05 deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc9pl4t_SH1p"
      },
      "source": [
        "class CNNtanh(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(CNNtanh, self).__init__()\n",
        "\n",
        "        # write code here to instantiate layers\n",
        "        # for example, self.conv = nn.Conv2d(1, 4, 3, 1, 1)\n",
        "        # creates a conv layer with 1 input channel, 4 output\n",
        "        # channels, a 3x3 kernel, and stride=padding=1\n",
        "\n",
        "        k, lst, npt, otpt = (k//3)*3, [], 1, 4\n",
        "\n",
        "        for i in range(0,3): #create 3 stages\n",
        "\n",
        "          for _ in range(0, int(k/3)): #create k/3 convultion+tanh layers per stage, add to lst\n",
        "            lst.extend([nn.Conv2d(npt, otpt, 3, 1, 1), nn.Tanh()])\n",
        "            npt = otpt\n",
        "     \n",
        "\n",
        "          #at the end of stage i, double, channels, add pooling later\n",
        "          lst.append(nn.AvgPool2d(2, stride=2))\n",
        "          otpt = otpt *2\n",
        "\n",
        "        self.mdl = nn.Sequential(*lst)\n",
        "\n",
        "        sz = otpt//2 * 3* 3\n",
        "        self.fc=nn.Linear(sz, 10)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                m.weight.data.normal_(0, 0.05)\n",
        "                m.bias.data.zero_()\n",
        "        \n",
        "    def forward(self, input):\n",
        "\n",
        "        # write code here to define how the output u is computed\n",
        "        # from the input and the model's layers\n",
        "        # for example, u = self.conv(input) defines u\n",
        "        # to be simply the output of self.conv given 'input'\n",
        "        u = self.mdl(input)\n",
        "        u = u.view(-1, np.prod(u.size()[1:4]))\n",
        "        u = self.fc(u)\n",
        "        return u"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx_4tOu4uiFW"
      },
      "source": [
        "The line below just instantiates the PyTorch Cross Entropy loss, whose inputs should be logits: hence the reason that the CNN should not have an activation after last (feedforward) layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4vxR4FOSH1p"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv54ar5_SH1p"
      },
      "source": [
        "Now, you should train CNNtanh with different values for k: your goal is to find the largest value for k such that the network achieves less than 20% error (either train or test) in 3 epochs. You should also choose an appropriate learning rate (but do not change the optimizer or the momentum settings!).\n",
        "\n",
        "Note that CNNs can easily achieve under 2% test error on MNIST, but we're choosing 20% as a threshold since you will be training each network for only 3 epochs.\n",
        "\n",
        "Remember to use values for k that are divisible by 3. When submitted, your notebook should have the training log of a network with two consecutive values for k (for example, 6 and 9) such that the network is 'trainable' with the smaller one but not 'trainable' with the larger one. It is fine for the training log to include runs with more than two values of k."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhQwwlUzSH1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f00893-43c1-44dc-c4b8-aa320bcbc1d4"
      },
      "source": [
        "k=0\n",
        "for i in range(1,100):\n",
        "  k = k+3*(i//6+1)\n",
        "  lr = .1\n",
        "\n",
        "  print(\"Training Tanh CNN with {} layers\".format(k))\n",
        "  model = CNNtanh(k).cuda()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "  train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader) \n",
        "  if test_errs >.20:  break"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Tanh CNN with 3 layers\n",
            "Epoch 000/003, Train Error 24.12% || Test Error 7.33%\n",
            "Epoch 001/003, Train Error 5.86% || Test Error 4.10%\n",
            "Epoch 002/003, Train Error 3.84% || Test Error 2.98%\n",
            "Training Tanh CNN with 6 layers\n",
            "Epoch 000/003, Train Error 54.64% || Test Error 7.55%\n",
            "Epoch 001/003, Train Error 5.06% || Test Error 3.45%\n",
            "Epoch 002/003, Train Error 3.16% || Test Error 2.75%\n",
            "Training Tanh CNN with 9 layers\n",
            "Epoch 000/003, Train Error 89.07% || Test Error 88.65%\n",
            "Epoch 001/003, Train Error 88.73% || Test Error 65.23%\n",
            "Epoch 002/003, Train Error 13.30% || Test Error 4.38%\n",
            "Training Tanh CNN with 12 layers\n",
            "Epoch 000/003, Train Error 89.04% || Test Error 88.65%\n",
            "Epoch 001/003, Train Error 88.96% || Test Error 88.65%\n",
            "Epoch 002/003, Train Error 88.95% || Test Error 88.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k8-1IeISH1q"
      },
      "source": [
        "### Better Initialization\n",
        "\n",
        "Next, we will change the initialization of the conv layers and see how it affects the trainability of deep networks. Instead of sampling from a Gaussian with a deviation of 0.05, you should sample from a Gaussian with a deviation $\\sigma = \\sqrt{\\frac{1}{k^2 \\cdot C_{out}}}$ or $\\sigma = \\sqrt{\\frac{1}{k^2 \\cdot C_{in}}}$, where $k$ is the kernel size ($k=3$ for 3x3 convolutions), $C_{in}$ is the number of input channels, and $C_{out}$ the number of output channels.\n",
        "\n",
        "The model below should be exactly like CNNtanh except for the standard deviation of the normal distribution used to initialize the conv layers.\n",
        "\n",
        "The paper 'Understanding the difficulty of training deep feedforward neural networks' by Glorot and Bengio provides some intuition behind such a choice for $\\sigma$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLCUVVAJfm25"
      },
      "source": [
        "class CNNtanh_newinit(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(CNNtanh_newinit, self).__init__()\n",
        "\n",
        "        # write code here to instantiate layers\n",
        "        # for example, self.conv = nn.Conv2d(1, 4, 3, 1, 1)\n",
        "        # creates a conv layer with 1 input channel, 4 output\n",
        "        # channels, a 3x3 kernel, and stride=padding=1\n",
        "        k, lst, npt, otpt = (k//3)*3, [], 1, 4\n",
        "\n",
        "        for i in range(0,3): #create 3 stages\n",
        "          for _ in range(0, int(k/3)): #create k/3 convultion+tanh layers per stage, add to lst\n",
        "            lst.extend([nn.Conv2d(npt, otpt, 3, 1, 1), nn.Tanh()])\n",
        "            npt = otpt\n",
        "     \n",
        "\n",
        "          #at the end of stage i, double, channels, add pooling layer\n",
        "          lst.append(nn.AvgPool2d(2, stride=2))\n",
        "          otpt = otpt *2\n",
        "\n",
        "        self.mdl = nn.Sequential(*lst)\n",
        "\n",
        "        sz = otpt//2 * 3* 3\n",
        "        self.fc=nn.Linear(sz, 10)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # insert code to compute sigma\n",
        "                sigma = math.sqrt(1/(9*m.out_channels))\n",
        "                m.weight.data.normal_(0, sigma)\n",
        "                m.bias.data.zero_()\n",
        "        \n",
        "    def forward(self, input):\n",
        "\n",
        "        # write code here to define how the output u is computed\n",
        "        # from the input and the model's layers\n",
        "        # for example, u = self.conv(input) defines u\n",
        "        # to be simply the output of self.conv given 'input'\n",
        "        u = self.mdl(input)\n",
        "        u = u.view(-1, np.prod(u.size()[1:4]))\n",
        "        u = self.fc(u)\n",
        "        return u"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_1LxL-Y0Q2A"
      },
      "source": [
        "Repeat the procedure of finding the maximum number of layers such that the network is still trainable, this time with CNNtanhinit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEGmH8CASH1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de2d600-475e-44d4-a91e-a235d2b42a1f"
      },
      "source": [
        "k=0\n",
        "for i in range(1,100):\n",
        "  k = k+3*(i//6+1)\n",
        "  lr = .01\n",
        "\n",
        "  print(\"\\nTraining Tanh CNN + new init with {} layers\".format(k))\n",
        "  model = CNNtanh_newinit(k).cuda()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "  train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "  if test_errs >.20:  break"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Tanh CNN + new init with 3 layers\n",
            "Epoch 000/003, Train Error 42.33% || Test Error 20.26%\n",
            "Epoch 001/003, Train Error 17.71% || Test Error 14.09%\n",
            "Epoch 002/003, Train Error 13.24% || Test Error 10.78%\n",
            "\n",
            "Training Tanh CNN + new init with 6 layers\n",
            "Epoch 000/003, Train Error 35.02% || Test Error 15.47%\n",
            "Epoch 001/003, Train Error 12.64% || Test Error 9.59%\n",
            "Epoch 002/003, Train Error 8.68% || Test Error 6.82%\n",
            "\n",
            "Training Tanh CNN + new init with 9 layers\n",
            "Epoch 000/003, Train Error 46.74% || Test Error 14.95%\n",
            "Epoch 001/003, Train Error 13.60% || Test Error 8.34%\n",
            "Epoch 002/003, Train Error 7.32% || Test Error 5.45%\n",
            "\n",
            "Training Tanh CNN + new init with 12 layers\n",
            "Epoch 000/003, Train Error 38.38% || Test Error 14.09%\n",
            "Epoch 001/003, Train Error 10.74% || Test Error 6.96%\n",
            "Epoch 002/003, Train Error 6.28% || Test Error 4.76%\n",
            "\n",
            "Training Tanh CNN + new init with 15 layers\n",
            "Epoch 000/003, Train Error 40.82% || Test Error 12.36%\n",
            "Epoch 001/003, Train Error 8.29% || Test Error 5.18%\n",
            "Epoch 002/003, Train Error 4.57% || Test Error 3.48%\n",
            "\n",
            "Training Tanh CNN + new init with 21 layers\n",
            "Epoch 000/003, Train Error 40.83% || Test Error 10.19%\n",
            "Epoch 001/003, Train Error 6.76% || Test Error 4.49%\n",
            "Epoch 002/003, Train Error 3.63% || Test Error 2.68%\n",
            "\n",
            "Training Tanh CNN + new init with 27 layers\n",
            "Epoch 000/003, Train Error 34.90% || Test Error 8.67%\n",
            "Epoch 001/003, Train Error 6.24% || Test Error 3.91%\n",
            "Epoch 002/003, Train Error 3.72% || Test Error 2.86%\n",
            "\n",
            "Training Tanh CNN + new init with 33 layers\n",
            "Epoch 000/003, Train Error 40.22% || Test Error 11.54%\n",
            "Epoch 001/003, Train Error 6.48% || Test Error 4.12%\n",
            "Epoch 002/003, Train Error 3.91% || Test Error 3.76%\n",
            "\n",
            "Training Tanh CNN + new init with 39 layers\n",
            "Epoch 000/003, Train Error 34.19% || Test Error 9.08%\n",
            "Epoch 001/003, Train Error 5.03% || Test Error 3.69%\n",
            "Epoch 002/003, Train Error 3.56% || Test Error 2.81%\n",
            "\n",
            "Training Tanh CNN + new init with 45 layers\n",
            "Epoch 000/003, Train Error 49.47% || Test Error 13.44%\n",
            "Epoch 001/003, Train Error 7.70% || Test Error 4.08%\n",
            "Epoch 002/003, Train Error 4.48% || Test Error 3.09%\n",
            "\n",
            "Training Tanh CNN + new init with 51 layers\n",
            "Epoch 000/003, Train Error 56.29% || Test Error 19.49%\n",
            "Epoch 001/003, Train Error 11.21% || Test Error 7.33%\n",
            "Epoch 002/003, Train Error 4.89% || Test Error 3.90%\n",
            "\n",
            "Training Tanh CNN + new init with 60 layers\n",
            "Epoch 000/003, Train Error 88.15% || Test Error 80.39%\n",
            "Epoch 001/003, Train Error 37.34% || Test Error 11.90%\n",
            "Epoch 002/003, Train Error 6.85% || Test Error 6.63%\n",
            "\n",
            "Training Tanh CNN + new init with 69 layers\n",
            "Epoch 000/003, Train Error 75.48% || Test Error 44.41%\n",
            "Epoch 001/003, Train Error 17.99% || Test Error 7.92%\n",
            "Epoch 002/003, Train Error 6.66% || Test Error 5.02%\n",
            "\n",
            "Training Tanh CNN + new init with 78 layers\n",
            "Epoch 000/003, Train Error 81.93% || Test Error 55.94%\n",
            "Epoch 001/003, Train Error 22.42% || Test Error 9.72%\n",
            "Epoch 002/003, Train Error 7.49% || Test Error 6.73%\n",
            "\n",
            "Training Tanh CNN + new init with 87 layers\n",
            "Epoch 000/003, Train Error 61.73% || Test Error 30.39%\n",
            "Epoch 001/003, Train Error 14.04% || Test Error 6.96%\n",
            "Epoch 002/003, Train Error 5.65% || Test Error 4.73%\n",
            "\n",
            "Training Tanh CNN + new init with 96 layers\n",
            "Epoch 000/003, Train Error 88.82% || Test Error 88.65%\n",
            "Epoch 001/003, Train Error 88.54% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 89.06% || Test Error 88.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IumG8z8QU_l7",
        "outputId": "54420eff-14a0-486e-9e29-6aa053eaca6a"
      },
      "source": [
        "#Try to find exact k by going back through with smaller steps\n",
        "k =  k-3*(i//6+1)\n",
        "print(f'\\nStarting back at k={k}')\n",
        "for i in range(0,100):\n",
        "  k = k+3*(i//6+1)\n",
        "  lr = .01\n",
        "\n",
        "  print(\"\\nTraining Tanh CNN + new init with {} layers\".format(k))\n",
        "  model = CNNtanh_newinit(k).cuda()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "  train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "  if test_errs >.20:  break"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting back at k=87\n",
            "\n",
            "Training Tanh CNN + new init with 90 layers\n",
            "Epoch 000/003, Train Error 88.79% || Test Error 88.65%\n",
            "Epoch 001/003, Train Error 82.06% || Test Error 52.27%\n",
            "Epoch 002/003, Train Error 30.66% || Test Error 14.08%\n",
            "\n",
            "Training Tanh CNN + new init with 93 layers\n",
            "Epoch 000/003, Train Error 61.07% || Test Error 14.18%\n",
            "Epoch 001/003, Train Error 9.53% || Test Error 6.42%\n",
            "Epoch 002/003, Train Error 4.70% || Test Error 5.19%\n",
            "\n",
            "Training Tanh CNN + new init with 96 layers\n",
            "Epoch 000/003, Train Error 83.73% || Test Error 67.98%\n",
            "Epoch 001/003, Train Error 41.26% || Test Error 20.96%\n",
            "Epoch 002/003, Train Error 17.91% || Test Error 11.57%\n",
            "\n",
            "Training Tanh CNN + new init with 99 layers\n",
            "Epoch 000/003, Train Error 85.18% || Test Error 57.39%\n",
            "Epoch 001/003, Train Error 42.42% || Test Error 23.09%\n",
            "Epoch 002/003, Train Error 18.06% || Test Error 11.63%\n",
            "\n",
            "Training Tanh CNN + new init with 102 layers\n",
            "Epoch 000/003, Train Error 88.86% || Test Error 88.65%\n",
            "Epoch 001/003, Train Error 86.14% || Test Error 75.78%\n",
            "Epoch 002/003, Train Error 66.64% || Test Error 54.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkVRwRkW0rkQ"
      },
      "source": [
        "### CNN with ELU activations\n",
        "\n",
        "In this section you should replace the Tanh activations of the previous network for Exponential Linear Units (ELUs). Complete CNNelu below, which should be exactly like CNNtanhinit except for ELU activations instead of Tanh (ELUs are readily available in PyTorch, check its documentation for more details)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFyLrax5SH1t"
      },
      "source": [
        "class CNNelu(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(CNNelu, self).__init__()\n",
        "\n",
        "        # write code here to instantiate layers\n",
        "        # for example, self.conv = nn.Conv2d(1, 4, 3, 1, 1)\n",
        "        # creates a conv layer with 1 input channel, 4 output\n",
        "        # channels, a 3x3 kernel, and stride=padding=1\n",
        "\n",
        "        k, lst, npt, otpt = (k//3)*3, [], 1, 4\n",
        "\n",
        "        for i in range(0,3): #create 3 stages\n",
        "          for _ in range(0, int(k/3)): #create k/3 convultion+tanh layers per stage, add to lst\n",
        "            lst.extend([nn.Conv2d(npt, otpt, 3, 1, 1), nn.ELU()])\n",
        "            npt = otpt\n",
        "     \n",
        "\n",
        "          #at the end of stage i, double, channels, add pooling layer\n",
        "          lst.append(nn.AvgPool2d(2, stride=2))\n",
        "          otpt = otpt *2\n",
        "\n",
        "        self.mdl = nn.Sequential(*lst)\n",
        "\n",
        "        sz = otpt//2 * 3* 3\n",
        "        self.fc=nn.Linear(sz, 10)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # insert code to compute sigma\n",
        "                sigma = math.sqrt(1/(9*m.out_channels))\n",
        "                m.weight.data.normal_(0, sigma)\n",
        "                m.bias.data.zero_()\n",
        "        \n",
        "    def forward(self, input):\n",
        "\n",
        "        # write code here to define how the output u is computed\n",
        "        # from the input and the model's layers\n",
        "        # for example, u = self.conv(input) defines u\n",
        "        # to be simply the output of self.conv given 'input'\n",
        "        u = self.mdl(input)\n",
        "        u = u.view(-1, np.prod(u.size()[1:4]))\n",
        "        u = self.fc(u)\n",
        "        return u"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2toBBTt1ZU5"
      },
      "source": [
        "Repeat the procedure of finding the maximum number of layers such that the network is still trainable, this time with CNNelu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmvJJuH73jgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb104070-90e4-4c04-e8d5-1728a2e05b2e"
      },
      "source": [
        "  k=0\n",
        "  for i in range(1,100):\n",
        "    k = k+3*(i//6+1)    \n",
        "    lr = .01 \n",
        "\n",
        "    print(\"\\nTraining ELU CNN, with {} layers\".format(k))\n",
        "    model = CNNelu(k).cuda()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "    if test_errs >.20:  break\n",
        "\n",
        "\n",
        "#Try to find exact k by going back through with smaller steps\n",
        "  k =  k-3*(i//6+1)\n",
        "  print(f'\\nStarting back at k={k} and proceeding with smaller steps.')\n",
        "  for i in range(0,100):\n",
        "    k = k+3*(i//6+1)\n",
        "\n",
        "    print(\"\\nTraining ELU CNN, with {} layers\".format(k))\n",
        "    model = CNNelu(k).cuda()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "    if test_errs >.20:  break\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training ELU CNN, with 3 layers\n",
            "Epoch 000/003, Train Error 26.46% || Test Error 8.57%\n",
            "Epoch 001/003, Train Error 7.51% || Test Error 6.04%\n",
            "Epoch 002/003, Train Error 5.48% || Test Error 3.93%\n",
            "\n",
            "Training ELU CNN, with 6 layers\n",
            "Epoch 000/003, Train Error 30.68% || Test Error 8.38%\n",
            "Epoch 001/003, Train Error 6.45% || Test Error 5.30%\n",
            "Epoch 002/003, Train Error 4.46% || Test Error 3.85%\n",
            "\n",
            "Training ELU CNN, with 9 layers\n",
            "Epoch 000/003, Train Error 44.22% || Test Error 8.33%\n",
            "Epoch 001/003, Train Error 5.69% || Test Error 3.75%\n",
            "Epoch 002/003, Train Error 3.23% || Test Error 2.55%\n",
            "\n",
            "Training ELU CNN, with 12 layers\n",
            "Epoch 000/003, Train Error 33.47% || Test Error 5.83%\n",
            "Epoch 001/003, Train Error 3.95% || Test Error 2.85%\n",
            "Epoch 002/003, Train Error 2.56% || Test Error 1.99%\n",
            "\n",
            "Training ELU CNN, with 15 layers\n",
            "Epoch 000/003, Train Error 36.40% || Test Error 6.22%\n",
            "Epoch 001/003, Train Error 4.36% || Test Error 3.60%\n",
            "Epoch 002/003, Train Error 2.82% || Test Error 2.53%\n",
            "\n",
            "Training ELU CNN, with 21 layers\n",
            "Epoch 000/003, Train Error 39.30% || Test Error 6.87%\n",
            "Epoch 001/003, Train Error 4.76% || Test Error 3.03%\n",
            "Epoch 002/003, Train Error 2.82% || Test Error 2.52%\n",
            "\n",
            "Training ELU CNN, with 27 layers\n",
            "Epoch 000/003, Train Error 46.40% || Test Error 5.88%\n",
            "Epoch 001/003, Train Error 4.43% || Test Error 2.87%\n",
            "Epoch 002/003, Train Error 2.82% || Test Error 2.01%\n",
            "\n",
            "Training ELU CNN, with 33 layers\n",
            "Epoch 000/003, Train Error 41.89% || Test Error 5.81%\n",
            "Epoch 001/003, Train Error 4.16% || Test Error 2.67%\n",
            "Epoch 002/003, Train Error 2.47% || Test Error 1.90%\n",
            "\n",
            "Training ELU CNN, with 39 layers\n",
            "Epoch 000/003, Train Error 69.30% || Test Error 11.60%\n",
            "Epoch 001/003, Train Error 6.15% || Test Error 3.38%\n",
            "Epoch 002/003, Train Error 3.29% || Test Error 2.16%\n",
            "\n",
            "Training ELU CNN, with 45 layers\n",
            "Epoch 000/003, Train Error 88.99% || Test Error 88.65%\n",
            "Epoch 001/003, Train Error 69.94% || Test Error 15.94%\n",
            "Epoch 002/003, Train Error 6.28% || Test Error 3.76%\n",
            "\n",
            "Training ELU CNN, with 51 layers\n",
            "Epoch 000/003, Train Error 69.51% || Test Error 26.97%\n",
            "Epoch 001/003, Train Error 10.27% || Test Error 4.33%\n",
            "Epoch 002/003, Train Error 4.02% || Test Error 3.16%\n",
            "\n",
            "Training ELU CNN, with 60 layers\n",
            "Epoch 000/003, Train Error 89.03% || Test Error 88.65%\n",
            "Epoch 001/003, Train Error 88.76% || Test Error 88.65%\n",
            "Epoch 002/003, Train Error 57.35% || Test Error 10.79%\n",
            "\n",
            "Training ELU CNN, with 69 layers\n",
            "Epoch 000/003, Train Error 88.86% || Test Error 88.65%\n",
            "Epoch 001/003, Train Error 78.76% || Test Error 46.01%\n",
            "Epoch 002/003, Train Error 21.26% || Test Error 8.41%\n",
            "\n",
            "Training ELU CNN, with 78 layers\n",
            "Epoch 000/003, Train Error 82.66% || Test Error 53.96%\n",
            "Epoch 001/003, Train Error 19.56% || Test Error 6.84%\n",
            "Epoch 002/003, Train Error 5.35% || Test Error 4.18%\n",
            "\n",
            "Training ELU CNN, with 87 layers\n",
            "Epoch 000/003, Train Error 82.45% || Test Error 43.33%\n",
            "Epoch 001/003, Train Error 25.32% || Test Error 9.93%\n",
            "Epoch 002/003, Train Error 11.07% || Test Error 6.37%\n",
            "\n",
            "Training ELU CNN, with 96 layers\n",
            "Epoch 000/003, Train Error 89.12% || Test Error 88.65%\n",
            "Epoch 001/003, Train Error 88.76% || Test Error 88.65%\n",
            "Epoch 002/003, Train Error 88.76% || Test Error 88.65%\n",
            "\n",
            "Starting back at k=87 and proceeding with smaller steps.\n",
            "\n",
            "Training ELU CNN, with 90 layers\n",
            "Epoch 000/003, Train Error 89.15% || Test Error 88.65%\n",
            "Epoch 001/003, Train Error 88.83% || Test Error 88.65%\n",
            "Epoch 002/003, Train Error 88.76% || Test Error 88.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjhF18tS1hVw"
      },
      "source": [
        "### CNN with Batch Normalization\n",
        "\n",
        "Next, you will check how batch normalization can make deep networks easier to train. Implement the network below, which should be exactly like CNNelu except for additional BatchNorm2d layers after each convolution (before the ELU activation).\n",
        "\n",
        "Note that BatchNorm2d modules require the number of channels as argument -- see the PyTorch documentation for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHqz0bqbDKEo"
      },
      "source": [
        "class CNNeluBN(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(CNNeluBN, self).__init__()\n",
        "\n",
        "        # write code here to instantiate layers\n",
        "        # for example, self.conv = nn.Conv2d(1, 4, 3, 1, 1)\n",
        "        # creates a conv layer with 1 input channel, 4 output\n",
        "        # channels, a 3x3 kernel, and stride=padding=1\n",
        "        k, lst, npt, otpt = (k//3)*3, [], 1, 4\n",
        "\n",
        "        for i in range(0,3): #create 3 stages\n",
        "          for _ in range(0, int(k/3)): #create k/3 convultion+tanh layers per stage, add to lst\n",
        "            lst.extend([nn.Conv2d(npt, otpt, 3, 1, 1), nn.BatchNorm2d(otpt), nn.ELU()]) \n",
        "            npt = otpt\n",
        "     \n",
        "\n",
        "          #at the end of stage i, double, channels, add pooling layer\n",
        "          lst.append(nn.AvgPool2d(2, stride=2))\n",
        "          otpt = otpt *2\n",
        "\n",
        "        self.mdl = nn.Sequential(*lst)\n",
        "\n",
        "        sz = otpt//2 * 3* 3\n",
        "        self.fc=nn.Linear(sz, 10)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # insert code to compute sigma\n",
        "                sigma = math.sqrt(1/(9*m.out_channels))\n",
        "                m.weight.data.normal_(0, sigma)\n",
        "                m.bias.data.zero_()\n",
        "        \n",
        "    def forward(self, input):\n",
        "        \n",
        "        # write code here to define how the output u is computed\n",
        "        # from the input and the model's layers\n",
        "        # for example, u = self.conv(input) defines u\n",
        "        # to be simply the output of self.conv given 'input'\n",
        "        u = self.mdl(input)\n",
        "        u = u.view(-1, np.prod(u.size()[1:4]))\n",
        "        u = self.fc(u)\n",
        "        return u"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WqDqDmG2eAo"
      },
      "source": [
        "Repeat the procedure of finding the maximum number of layers such that the network is still trainable, this time with CNNeluBN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTDiRg9kERsH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72a1ddb-250f-4a71-801a-ec7e24e3833a"
      },
      "source": [
        "  k=0\n",
        "  for i in range(1,100):\n",
        "    k = k+3*(i//6+1)    \n",
        "    lr = .01  \n",
        "\n",
        "    print(\"\\nTraining ELU CNN + BN with {} layers\".format(k))\n",
        "    model = CNNeluBN(k).cuda()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "    if test_errs >.2: \n",
        "      #try again\n",
        "      model = ResNet(k).cuda()\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "      train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "      if test_errs >.2: break \n",
        "      \n",
        "#Try to find exact k by going back through with smaller steps\n",
        "  k =  k-3*(i//6+1)\n",
        "  print(f'\\nStarting back at k={k} and proceeding with smaller steps.')\n",
        "  for i in range(0,100):\n",
        "    k = k+3*(i//6+1)\n",
        "\n",
        "    print(\"\\nTraining ELU CNN + BN with {} layers\".format(k))\n",
        "    model = CNNeluBN(k).cuda()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "    if test_errs >.2: break\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training ELU CNN + BN with 3 layers\n",
            "Epoch 000/003, Train Error 13.00% || Test Error 3.88%\n",
            "Epoch 001/003, Train Error 3.65% || Test Error 2.18%\n",
            "Epoch 002/003, Train Error 2.30% || Test Error 1.87%\n",
            "\n",
            "Training ELU CNN + BN with 6 layers\n",
            "Epoch 000/003, Train Error 11.81% || Test Error 3.15%\n",
            "Epoch 001/003, Train Error 3.17% || Test Error 1.77%\n",
            "Epoch 002/003, Train Error 2.06% || Test Error 1.67%\n",
            "\n",
            "Training ELU CNN + BN with 9 layers\n",
            "Epoch 000/003, Train Error 9.33% || Test Error 2.10%\n",
            "Epoch 001/003, Train Error 2.42% || Test Error 1.59%\n",
            "Epoch 002/003, Train Error 1.73% || Test Error 1.29%\n",
            "\n",
            "Training ELU CNN + BN with 12 layers\n",
            "Epoch 000/003, Train Error 7.87% || Test Error 1.97%\n",
            "Epoch 001/003, Train Error 12.50% || Test Error 4.12%\n",
            "Epoch 002/003, Train Error 3.38% || Test Error 2.98%\n",
            "\n",
            "Training ELU CNN + BN with 15 layers\n",
            "Epoch 000/003, Train Error 8.44% || Test Error 2.58%\n",
            "Epoch 001/003, Train Error 2.96% || Test Error 2.61%\n",
            "Epoch 002/003, Train Error 1.88% || Test Error 1.55%\n",
            "\n",
            "Training ELU CNN + BN with 21 layers\n",
            "Epoch 000/003, Train Error 7.81% || Test Error 1.91%\n",
            "Epoch 001/003, Train Error 2.53% || Test Error 2.07%\n",
            "Epoch 002/003, Train Error 1.79% || Test Error 1.29%\n",
            "\n",
            "Training ELU CNN + BN with 27 layers\n",
            "Epoch 000/003, Train Error 8.70% || Test Error 2.06%\n",
            "Epoch 001/003, Train Error 2.55% || Test Error 1.74%\n",
            "Epoch 002/003, Train Error 1.63% || Test Error 0.94%\n",
            "\n",
            "Training ELU CNN + BN with 33 layers\n",
            "Epoch 000/003, Train Error 10.28% || Test Error 3.12%\n",
            "Epoch 001/003, Train Error 6.13% || Test Error 2.34%\n",
            "Epoch 002/003, Train Error 2.22% || Test Error 1.44%\n",
            "\n",
            "Training ELU CNN + BN with 39 layers\n",
            "Epoch 000/003, Train Error 9.64% || Test Error 2.32%\n",
            "Epoch 001/003, Train Error 2.83% || Test Error 2.42%\n",
            "Epoch 002/003, Train Error 2.03% || Test Error 1.75%\n",
            "\n",
            "Training ELU CNN + BN with 45 layers\n",
            "Epoch 000/003, Train Error 12.93% || Test Error 2.84%\n",
            "Epoch 001/003, Train Error 3.25% || Test Error 2.55%\n",
            "Epoch 002/003, Train Error 2.21% || Test Error 1.98%\n",
            "\n",
            "Training ELU CNN + BN with 51 layers\n",
            "Epoch 000/003, Train Error 11.78% || Test Error 4.09%\n",
            "Epoch 001/003, Train Error 89.44% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 90.13% || Test Error 90.20%\n",
            "\n",
            "Starting back at k=45 and proceeding with smaller steps.\n",
            "\n",
            "Training ELU CNN + BN with 48 layers\n",
            "Epoch 000/003, Train Error 12.23% || Test Error 2.61%\n",
            "Epoch 001/003, Train Error 3.27% || Test Error 2.07%\n",
            "Epoch 002/003, Train Error 1.93% || Test Error 1.40%\n",
            "\n",
            "Training ELU CNN + BN with 51 layers\n",
            "Epoch 000/003, Train Error 14.18% || Test Error 4.06%\n",
            "Epoch 001/003, Train Error 4.08% || Test Error 2.43%\n",
            "Epoch 002/003, Train Error 2.50% || Test Error 3.02%\n",
            "\n",
            "Training ELU CNN + BN with 54 layers\n",
            "Epoch 000/003, Train Error 13.24% || Test Error 3.69%\n",
            "Epoch 001/003, Train Error 7.56% || Test Error 2.94%\n",
            "Epoch 002/003, Train Error 2.54% || Test Error 1.91%\n",
            "\n",
            "Training ELU CNN + BN with 57 layers\n",
            "Epoch 000/003, Train Error 17.90% || Test Error 4.63%\n",
            "Epoch 001/003, Train Error 89.42% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 90.13% || Test Error 90.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRiNhcbdzYsi"
      },
      "source": [
        "I am restarting at 57, because it didnt follow the observed trend for the model to fail at that point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1kcb9iIzROn",
        "outputId": "1da857ea-c1cc-446d-c9de-a5c26f596f73"
      },
      "source": [
        "  k=57\n",
        "  print(f'\\nStarting back at k={k} and proceeding with smaller steps.')\n",
        "  for i in range(0,100):\n",
        "    k = k+3*(i//6+1)\n",
        "\n",
        "    print(\"\\nTraining ELU CNN + BN with {} layers\".format(k))\n",
        "    model = CNNeluBN(k).cuda()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "    if test_errs >.2: \n",
        "      #try again\n",
        "      model = ResNet(k).cuda()\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "      train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "      if test_errs >.2: break "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting back at k=57 and proceeding with smaller steps.\n",
            "\n",
            "Training ELU CNN + BN with 60 layers\n",
            "Epoch 000/003, Train Error 15.24% || Test Error 3.76%\n",
            "Epoch 001/003, Train Error 3.73% || Test Error 2.39%\n",
            "Epoch 002/003, Train Error 2.32% || Test Error 2.09%\n",
            "\n",
            "Training ELU CNN + BN with 63 layers\n",
            "Epoch 000/003, Train Error 15.37% || Test Error 4.28%\n",
            "Epoch 001/003, Train Error 4.19% || Test Error 2.32%\n",
            "Epoch 002/003, Train Error 2.66% || Test Error 2.23%\n",
            "\n",
            "Training ELU CNN + BN with 66 layers\n",
            "Epoch 000/003, Train Error 16.57% || Test Error 4.82%\n",
            "Epoch 001/003, Train Error 15.17% || Test Error 4.78%\n",
            "Epoch 002/003, Train Error 4.25% || Test Error 3.67%\n",
            "\n",
            "Training ELU CNN + BN with 69 layers\n",
            "Epoch 000/003, Train Error 19.56% || Test Error 4.51%\n",
            "Epoch 001/003, Train Error 4.54% || Test Error 3.56%\n",
            "Epoch 002/003, Train Error 2.89% || Test Error 2.25%\n",
            "\n",
            "Training ELU CNN + BN with 72 layers\n",
            "Epoch 000/003, Train Error 16.10% || Test Error 3.28%\n",
            "Epoch 001/003, Train Error 23.95% || Test Error 6.45%\n",
            "Epoch 002/003, Train Error 6.30% || Test Error 6.08%\n",
            "\n",
            "Training ELU CNN + BN with 75 layers\n",
            "Epoch 000/003, Train Error 21.76% || Test Error 6.58%\n",
            "Epoch 001/003, Train Error 5.22% || Test Error 3.29%\n",
            "Epoch 002/003, Train Error 3.09% || Test Error 3.19%\n",
            "\n",
            "Training ELU CNN + BN with 81 layers\n",
            "Epoch 000/003, Train Error 20.61% || Test Error 6.39%\n",
            "Epoch 001/003, Train Error 4.94% || Test Error 2.72%\n",
            "Epoch 002/003, Train Error 3.07% || Test Error 3.38%\n",
            "\n",
            "Training ELU CNN + BN with 87 layers\n",
            "Epoch 000/003, Train Error 23.49% || Test Error 7.77%\n",
            "Epoch 001/003, Train Error 4.98% || Test Error 3.37%\n",
            "Epoch 002/003, Train Error 3.15% || Test Error 2.32%\n",
            "\n",
            "Training ELU CNN + BN with 93 layers\n",
            "Epoch 000/003, Train Error 29.76% || Test Error 8.34%\n",
            "Epoch 001/003, Train Error 7.02% || Test Error 3.90%\n",
            "Epoch 002/003, Train Error 3.81% || Test Error 2.66%\n",
            "\n",
            "Training ELU CNN + BN with 99 layers\n",
            "Epoch 000/003, Train Error 28.44% || Test Error 8.52%\n",
            "Epoch 001/003, Train Error 7.17% || Test Error 5.54%\n",
            "Epoch 002/003, Train Error 4.27% || Test Error 3.49%\n",
            "\n",
            "Training ELU CNN + BN with 105 layers\n",
            "Epoch 000/003, Train Error 29.22% || Test Error 6.04%\n",
            "Epoch 001/003, Train Error 9.18% || Test Error 4.19%\n",
            "Epoch 002/003, Train Error 3.66% || Test Error 3.22%\n",
            "\n",
            "Training ELU CNN + BN with 111 layers\n",
            "Epoch 000/003, Train Error 30.29% || Test Error 6.81%\n",
            "Epoch 001/003, Train Error 12.93% || Test Error 6.70%\n",
            "Epoch 002/003, Train Error 5.51% || Test Error 4.93%\n",
            "\n",
            "Training ELU CNN + BN with 120 layers\n",
            "Epoch 000/003, Train Error 40.16% || Test Error 15.01%\n",
            "Epoch 001/003, Train Error 88.00% || Test Error 88.62%\n",
            "Epoch 002/003, Train Error 89.46% || Test Error 89.72%\n",
            "Epoch 000/003, Train Error 21.22% || Test Error 4.39%\n",
            "Epoch 001/003, Train Error 3.96% || Test Error 3.06%\n",
            "Epoch 002/003, Train Error 2.57% || Test Error 1.95%\n",
            "\n",
            "Training ELU CNN + BN with 129 layers\n",
            "Epoch 000/003, Train Error 65.93% || Test Error 33.98%\n",
            "Epoch 001/003, Train Error 25.82% || Test Error 14.45%\n",
            "Epoch 002/003, Train Error 10.99% || Test Error 9.57%\n",
            "\n",
            "Training ELU CNN + BN with 138 layers\n",
            "Epoch 000/003, Train Error 67.96% || Test Error 33.26%\n",
            "Epoch 001/003, Train Error 24.23% || Test Error 13.85%\n",
            "Epoch 002/003, Train Error 11.92% || Test Error 8.59%\n",
            "\n",
            "Training ELU CNN + BN with 147 layers\n",
            "Epoch 000/003, Train Error 48.42% || Test Error 21.20%\n",
            "Epoch 001/003, Train Error 20.43% || Test Error 10.43%\n",
            "Epoch 002/003, Train Error 8.62% || Test Error 10.17%\n",
            "\n",
            "Training ELU CNN + BN with 156 layers\n",
            "Epoch 000/003, Train Error 49.95% || Test Error 20.65%\n",
            "Epoch 001/003, Train Error 27.15% || Test Error 16.28%\n",
            "Epoch 002/003, Train Error 13.61% || Test Error 11.99%\n",
            "\n",
            "Training ELU CNN + BN with 165 layers\n",
            "Epoch 000/003, Train Error 68.87% || Test Error 37.30%\n",
            "Epoch 001/003, Train Error 48.87% || Test Error 36.04%\n",
            "Epoch 002/003, Train Error 23.40% || Test Error 16.81%\n",
            "\n",
            "Training ELU CNN + BN with 177 layers\n",
            "Epoch 000/003, Train Error 82.81% || Test Error 68.10%\n",
            "Epoch 001/003, Train Error 87.93% || Test Error 88.65%\n",
            "Epoch 002/003, Train Error 89.31% || Test Error 90.20%\n",
            "Epoch 000/003, Train Error 42.48% || Test Error 16.54%\n",
            "Epoch 001/003, Train Error 12.89% || Test Error 9.47%\n",
            "Epoch 002/003, Train Error 8.05% || Test Error 6.42%\n",
            "\n",
            "Training ELU CNN + BN with 189 layers\n",
            "Epoch 000/003, Train Error 78.58% || Test Error 62.42%\n",
            "Epoch 001/003, Train Error 54.28% || Test Error 44.82%\n",
            "Epoch 002/003, Train Error 38.87% || Test Error 32.32%\n",
            "Epoch 000/003, Train Error 26.97% || Test Error 10.38%\n",
            "Epoch 001/003, Train Error 8.18% || Test Error 5.04%\n",
            "Epoch 002/003, Train Error 5.48% || Test Error 4.37%\n",
            "\n",
            "Training ELU CNN + BN with 201 layers\n",
            "Epoch 000/003, Train Error 81.70% || Test Error 82.51%\n",
            "Epoch 001/003, Train Error 88.36% || Test Error 85.65%\n",
            "Epoch 002/003, Train Error 86.57% || Test Error 84.67%\n",
            "Epoch 000/003, Train Error 29.64% || Test Error 8.76%\n",
            "Epoch 001/003, Train Error 7.66% || Test Error 6.33%\n",
            "Epoch 002/003, Train Error 5.46% || Test Error 4.56%\n",
            "\n",
            "Training ELU CNN + BN with 213 layers\n",
            "Epoch 000/003, Train Error 70.70% || Test Error 60.38%\n",
            "Epoch 001/003, Train Error 66.28% || Test Error 67.66%\n",
            "Epoch 002/003, Train Error 60.38% || Test Error 56.04%\n",
            "Epoch 000/003, Train Error 44.91% || Test Error 18.52%\n",
            "Epoch 001/003, Train Error 14.53% || Test Error 12.55%\n",
            "Epoch 002/003, Train Error 10.68% || Test Error 8.88%\n",
            "\n",
            "Training ELU CNN + BN with 225 layers\n",
            "Epoch 000/003, Train Error 89.00% || Test Error 88.37%\n",
            "Epoch 001/003, Train Error 89.39% || Test Error 89.71%\n",
            "Epoch 002/003, Train Error 89.28% || Test Error 88.65%\n",
            "Epoch 000/003, Train Error 42.25% || Test Error 12.00%\n",
            "Epoch 001/003, Train Error 89.45% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 90.13% || Test Error 90.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LOZfZtl2gcg"
      },
      "source": [
        "### Residual Networks\n",
        "\n",
        "Finally, you experiment adding residual connections to a CNN.\n",
        "\n",
        "To implement the model below, you should add a 'skip connection' to 'Conv->BatchNorm->ELU' blocks whenever the shape of the block's input and output are the same: this will be the case for every such block except for the first ones in each stage, as they double the number of channels.\n",
        "\n",
        "More specifically, you should change $u = ELU(BatchNorm(Conv(x)))$ to $u = ELU(BatchNorm(Conv(x))) + x$, where $x$ and $u$ denote the block's input and output, respectively.\n",
        "\n",
        "You should take your CNNeluBN implementation and add skip-connections as described above.\n",
        "\n",
        "Note that there are key differences between the resulting model and the actual ResNet proposed by He et al. in 'Deep Residual Learning for Image Recognition', for example the use of ELU activations instead of ReLU and the exact position of skip-connections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA6ItpH-GpK_"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        # write code here to instantiate layers\n",
        "        # for example, self.conv = nn.Conv2d(1, 4, 3, 1, 1)\n",
        "        # creates a conv layer with 1 input channel, 4 output\n",
        "        # channels, a 3x3 kernel, and stride=padding=1\n",
        "        k, npt, otpt = (k//3)*3, 1, 4\n",
        "        lst = nn.ModuleList()  \n",
        "\n",
        "\n",
        "        for i in range(0,3): #create 3 stages\n",
        "          for _ in range(0, int(k/3)): #create k/3 convultion blocks per stage, add to lst\n",
        "            lst.extend([nn.Conv2d(npt, otpt, 3, 1, 1), nn.BatchNorm2d(otpt), nn.ELU()]) #be cautious with untested code\n",
        "            npt = otpt\n",
        "     \n",
        "\n",
        "          #at the end of stage i, double, channels, add pooling layer\n",
        "          lst.append(nn.AvgPool2d(2, stride=2))\n",
        "          otpt = otpt *2\n",
        "\n",
        "        self.mdl = lst\n",
        "\n",
        "        sz = otpt//2 * 3* 3\n",
        "        self.fc=nn.Linear(sz, 10)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # insert code to compute sigma\n",
        "                sigma = math.sqrt(1/(9*m.out_channels))\n",
        "                m.weight.data.normal_(0, sigma)\n",
        "                m.bias.data.zero_()\n",
        "        \n",
        "        \n",
        "    def forward(self, input):\n",
        "        \n",
        "        # write code here to define how the output u is computed\n",
        "        # from the input and the model's layers\n",
        "        # for example, u = self.conv(input) defines u\n",
        "        # to be simply the output of self.conv given 'input'\n",
        "        u = input\n",
        "\n",
        "        #do main part of model\n",
        "        for layer in self.mdl:\n",
        "          if isinstance(layer, nn.Conv2d): \n",
        "            u_block = u #save input when first encounter a new block\n",
        "            skip = layer.in_channels == layer.out_channels\n",
        "          if isinstance(layer, nn.ELU) and skip: u = layer(u)+u_block #when in == out channels and is ELU, do skip\n",
        "          else: u = layer(u)\n",
        "\n",
        "        #do fully connected  \n",
        "        u = u.view(-1, np.prod(u.size()[1:4]))\n",
        "        u = self.fc(u)\n",
        "        return u"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWHYn08j5kqb"
      },
      "source": [
        "Repeat the procedure of finding the maximum number of layers such that the network is still trainable, this time with the 'ResNet' model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UJLiaGzJv1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71285ff2-34d4-44ae-b5c2-5e8bcbaadeb5"
      },
      "source": [
        "  k=0\n",
        "  for i in range(1,100):\n",
        "    k = k+3*(i//6+1)    \n",
        "    lr = .01  \n",
        "\n",
        "    print(\"\\nTraining ResNet with {} layers\".format(k))\n",
        "    model = ResNet(k).cuda()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "    if test_errs >.2: \n",
        "      #try again\n",
        "      model = ResNet(k).cuda()\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "      train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "      if test_errs >.2: break \n",
        "      \n",
        "#Try to find exact k by going back through with smaller steps\n",
        "  k =  k-3*(i//6+1)\n",
        "  print(f'\\nStarting back at k={k} and proceeding with smaller steps.')\n",
        "  for i in range(0,100):\n",
        "    k = k+3*(i//6+1)\n",
        "\n",
        "    print(\"\\nTraining ResNet with {} layers\".format(k))\n",
        "    model = ResNet(k).cuda()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "    if test_errs >.2: break\n",
        "\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training ResNet with 3 layers\n",
            "Epoch 000/003, Train Error 15.85% || Test Error 4.86%\n",
            "Epoch 001/003, Train Error 4.23% || Test Error 2.59%\n",
            "Epoch 002/003, Train Error 2.76% || Test Error 2.01%\n",
            "\n",
            "Training ResNet with 6 layers\n",
            "Epoch 000/003, Train Error 10.08% || Test Error 2.78%\n",
            "Epoch 001/003, Train Error 88.12% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 90.13% || Test Error 90.20%\n",
            "Epoch 000/003, Train Error 10.80% || Test Error 2.86%\n",
            "Epoch 001/003, Train Error 3.57% || Test Error 2.17%\n",
            "Epoch 002/003, Train Error 1.96% || Test Error 1.92%\n",
            "\n",
            "Training ResNet with 9 layers\n",
            "Epoch 000/003, Train Error 8.79% || Test Error 3.03%\n",
            "Epoch 001/003, Train Error 2.62% || Test Error 1.94%\n",
            "Epoch 002/003, Train Error 1.80% || Test Error 1.51%\n",
            "\n",
            "Training ResNet with 12 layers\n",
            "Epoch 000/003, Train Error 8.51% || Test Error 2.22%\n",
            "Epoch 001/003, Train Error 2.62% || Test Error 1.99%\n",
            "Epoch 002/003, Train Error 1.79% || Test Error 1.50%\n",
            "\n",
            "Training ResNet with 15 layers\n",
            "Epoch 000/003, Train Error 6.92% || Test Error 2.33%\n",
            "Epoch 001/003, Train Error 2.54% || Test Error 2.23%\n",
            "Epoch 002/003, Train Error 1.65% || Test Error 1.42%\n",
            "\n",
            "Training ResNet with 21 layers\n",
            "Epoch 000/003, Train Error 7.34% || Test Error 2.63%\n",
            "Epoch 001/003, Train Error 87.55% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 90.13% || Test Error 90.20%\n",
            "Epoch 000/003, Train Error 6.87% || Test Error 2.14%\n",
            "Epoch 001/003, Train Error 2.54% || Test Error 1.50%\n",
            "Epoch 002/003, Train Error 1.46% || Test Error 1.16%\n",
            "\n",
            "Training ResNet with 27 layers\n",
            "Epoch 000/003, Train Error 7.46% || Test Error 2.25%\n",
            "Epoch 001/003, Train Error 2.47% || Test Error 1.64%\n",
            "Epoch 002/003, Train Error 1.54% || Test Error 1.75%\n",
            "\n",
            "Training ResNet with 33 layers\n",
            "Epoch 000/003, Train Error 6.80% || Test Error 2.08%\n",
            "Epoch 001/003, Train Error 2.34% || Test Error 1.54%\n",
            "Epoch 002/003, Train Error 1.60% || Test Error 1.76%\n",
            "\n",
            "Training ResNet with 39 layers\n",
            "Epoch 000/003, Train Error 7.78% || Test Error 2.42%\n",
            "Epoch 001/003, Train Error 85.26% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 90.13% || Test Error 90.20%\n",
            "Epoch 000/003, Train Error 6.90% || Test Error 2.79%\n",
            "Epoch 001/003, Train Error 89.14% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 90.13% || Test Error 90.20%\n",
            "\n",
            "Starting back at k=33 and proceeding with smaller steps.\n",
            "\n",
            "Training ResNet with 36 layers\n",
            "Epoch 000/003, Train Error 7.71% || Test Error 2.14%\n",
            "Epoch 001/003, Train Error 2.32% || Test Error 1.64%\n",
            "Epoch 002/003, Train Error 1.59% || Test Error 1.55%\n",
            "\n",
            "Training ResNet with 39 layers\n",
            "Epoch 000/003, Train Error 6.82% || Test Error 2.25%\n",
            "Epoch 001/003, Train Error 2.71% || Test Error 1.41%\n",
            "Epoch 002/003, Train Error 1.53% || Test Error 1.50%\n",
            "\n",
            "Training ResNet with 42 layers\n",
            "Epoch 000/003, Train Error 7.76% || Test Error 2.23%\n",
            "Epoch 001/003, Train Error 2.36% || Test Error 2.07%\n",
            "Epoch 002/003, Train Error 1.66% || Test Error 1.37%\n",
            "\n",
            "Training ResNet with 45 layers\n",
            "Epoch 000/003, Train Error 8.95% || Test Error 2.69%\n",
            "Epoch 001/003, Train Error 6.35% || Test Error 2.49%\n",
            "Epoch 002/003, Train Error 1.98% || Test Error 1.89%\n",
            "\n",
            "Training ResNet with 48 layers\n",
            "Epoch 000/003, Train Error 9.92% || Test Error 2.65%\n",
            "Epoch 001/003, Train Error 2.52% || Test Error 1.71%\n",
            "Epoch 002/003, Train Error 1.75% || Test Error 1.83%\n",
            "\n",
            "Training ResNet with 51 layers\n",
            "Epoch 000/003, Train Error 8.59% || Test Error 2.81%\n",
            "Epoch 001/003, Train Error 2.68% || Test Error 1.97%\n",
            "Epoch 002/003, Train Error 1.92% || Test Error 1.60%\n",
            "\n",
            "Training ResNet with 57 layers\n",
            "Epoch 000/003, Train Error 9.93% || Test Error 2.66%\n",
            "Epoch 001/003, Train Error 89.57% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 90.13% || Test Error 90.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gt6NPTFp8-d",
        "outputId": "d61463e0-35f8-4b3b-bd05-281af7add605"
      },
      "source": [
        "  k =  51\n",
        "  print(f'\\nStarting back at k={k} and proceeding with smaller steps.')\n",
        "  for i in range(0,100):\n",
        "    k = k+3*(i//6+1)\n",
        "\n",
        "    print(\"\\nTraining ResNet with {} layers\".format(k))\n",
        "    model = ResNet(k).cuda()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "    if test_errs >.2: \n",
        "      #try again\n",
        "      model = ResNet(k).cuda()\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "      train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "      if test_errs >.2: break \n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting back at k=51 and proceeding with smaller steps.\n",
            "\n",
            "Training ResNet with 54 layers\n",
            "Epoch 000/003, Train Error 7.72% || Test Error 2.33%\n",
            "Epoch 001/003, Train Error 2.62% || Test Error 1.58%\n",
            "Epoch 002/003, Train Error 1.65% || Test Error 1.68%\n",
            "\n",
            "Training ResNet with 57 layers\n",
            "Epoch 000/003, Train Error 8.78% || Test Error 2.15%\n",
            "Epoch 001/003, Train Error 2.51% || Test Error 1.58%\n",
            "Epoch 002/003, Train Error 1.63% || Test Error 1.40%\n",
            "\n",
            "Training ResNet with 60 layers\n",
            "Epoch 000/003, Train Error 9.39% || Test Error 2.35%\n",
            "Epoch 001/003, Train Error 89.05% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 90.13% || Test Error 90.20%\n",
            "Epoch 000/003, Train Error 7.84% || Test Error 2.43%\n",
            "Epoch 001/003, Train Error 2.54% || Test Error 1.77%\n",
            "Epoch 002/003, Train Error 1.63% || Test Error 1.35%\n",
            "\n",
            "Training ResNet with 63 layers\n",
            "Epoch 000/003, Train Error 10.43% || Test Error 2.45%\n",
            "Epoch 001/003, Train Error 2.50% || Test Error 1.74%\n",
            "Epoch 002/003, Train Error 1.67% || Test Error 1.51%\n",
            "\n",
            "Training ResNet with 66 layers\n",
            "Epoch 000/003, Train Error 11.07% || Test Error 3.24%\n",
            "Epoch 001/003, Train Error 2.80% || Test Error 1.89%\n",
            "Epoch 002/003, Train Error 1.92% || Test Error 1.50%\n",
            "\n",
            "Training ResNet with 69 layers\n",
            "Epoch 000/003, Train Error 10.27% || Test Error 2.50%\n",
            "Epoch 001/003, Train Error 2.61% || Test Error 1.96%\n",
            "Epoch 002/003, Train Error 1.75% || Test Error 1.36%\n",
            "\n",
            "Training ResNet with 75 layers\n",
            "Epoch 000/003, Train Error 12.01% || Test Error 3.87%\n",
            "Epoch 001/003, Train Error 3.56% || Test Error 2.44%\n",
            "Epoch 002/003, Train Error 2.51% || Test Error 2.12%\n",
            "\n",
            "Training ResNet with 81 layers\n",
            "Epoch 000/003, Train Error 11.77% || Test Error 3.08%\n",
            "Epoch 001/003, Train Error 3.12% || Test Error 2.26%\n",
            "Epoch 002/003, Train Error 2.16% || Test Error 1.62%\n",
            "\n",
            "Training ResNet with 87 layers\n",
            "Epoch 000/003, Train Error 13.58% || Test Error 3.68%\n",
            "Epoch 001/003, Train Error 3.90% || Test Error 2.65%\n",
            "Epoch 002/003, Train Error 2.56% || Test Error 1.97%\n",
            "\n",
            "Training ResNet with 93 layers\n",
            "Epoch 000/003, Train Error 17.84% || Test Error 5.00%\n",
            "Epoch 001/003, Train Error 4.12% || Test Error 2.95%\n",
            "Epoch 002/003, Train Error 3.02% || Test Error 2.27%\n",
            "\n",
            "Training ResNet with 99 layers\n",
            "Epoch 000/003, Train Error 21.23% || Test Error 7.17%\n",
            "Epoch 001/003, Train Error 5.24% || Test Error 3.38%\n",
            "Epoch 002/003, Train Error 3.20% || Test Error 2.52%\n",
            "\n",
            "Training ResNet with 105 layers\n",
            "Epoch 000/003, Train Error 15.42% || Test Error 5.56%\n",
            "Epoch 001/003, Train Error 4.77% || Test Error 3.35%\n",
            "Epoch 002/003, Train Error 3.33% || Test Error 3.43%\n",
            "\n",
            "Training ResNet with 114 layers\n",
            "Epoch 000/003, Train Error 22.82% || Test Error 8.42%\n",
            "Epoch 001/003, Train Error 7.19% || Test Error 5.63%\n",
            "Epoch 002/003, Train Error 4.51% || Test Error 3.89%\n",
            "\n",
            "Training ResNet with 123 layers\n",
            "Epoch 000/003, Train Error 20.18% || Test Error 6.18%\n",
            "Epoch 001/003, Train Error 5.19% || Test Error 3.56%\n",
            "Epoch 002/003, Train Error 3.55% || Test Error 2.62%\n",
            "\n",
            "Training ResNet with 132 layers\n",
            "Epoch 000/003, Train Error 31.78% || Test Error 10.88%\n",
            "Epoch 001/003, Train Error 10.13% || Test Error 7.34%\n",
            "Epoch 002/003, Train Error 6.88% || Test Error 5.48%\n",
            "\n",
            "Training ResNet with 141 layers\n",
            "Epoch 000/003, Train Error 46.22% || Test Error 11.37%\n",
            "Epoch 001/003, Train Error 85.44% || Test Error 68.01%\n",
            "Epoch 002/003, Train Error 28.66% || Test Error 10.31%\n",
            "\n",
            "Training ResNet with 150 layers\n",
            "Epoch 000/003, Train Error 38.76% || Test Error 18.30%\n",
            "Epoch 001/003, Train Error 12.81% || Test Error 8.21%\n",
            "Epoch 002/003, Train Error 8.87% || Test Error 6.72%\n",
            "\n",
            "Training ResNet with 159 layers\n",
            "Epoch 000/003, Train Error 33.65% || Test Error 16.02%\n",
            "Epoch 001/003, Train Error 17.15% || Test Error 9.19%\n",
            "Epoch 002/003, Train Error 7.38% || Test Error 6.03%\n",
            "\n",
            "Training ResNet with 171 layers\n",
            "Epoch 000/003, Train Error 37.71% || Test Error 8.18%\n",
            "Epoch 001/003, Train Error 89.22% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 90.13% || Test Error 90.20%\n",
            "Epoch 000/003, Train Error 44.42% || Test Error 12.43%\n",
            "Epoch 001/003, Train Error 85.55% || Test Error 88.65%\n",
            "Epoch 002/003, Train Error 86.62% || Test Error 53.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdSKAR4U51pQ"
      },
      "source": [
        "**<font color='blue'>\n",
        "    Summarize your results and observations regarding the experiments above. What was the maximum number of layers for each of the five models such that training remained successful? Briefly discuss why you think each modification helped/harmed the trainability of deep models.\n",
        "</font>**\n",
        "\n",
        "**<font color='red'> --------------------------------------------------------------------- ANSWER (BEGIN) ---------------------------------------------------------------------\n",
        "</font>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogEVn07T5dti"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isk0cAPNcour"
      },
      "source": [
        "## Short Answer Responses\n",
        "\n",
        "### CNN w/Tanh Activations\n",
        "  - The max layer that I reached was 12. \n",
        "\n",
        "### CNN w/Tanh Activations + Better Initialization\n",
        "  -  When I added the suggested initalization, the max k went up to 96 or 102. This is a significant jump. Since each layer was initalized in a way that took in account its own dimensions as opposed to just being random, I would expect to see much better results.\n",
        "  \n",
        "### CNN w/ Better Activation + ELU Activation\n",
        "  -  This architecture made it to around k=90. So, it actually did worse than the tanh activation. It is not clear to me, why this happened as ReLu seems better regarded in the ML community. Perhaps, something about this architecture generated negative values and forced our gradients to 0. \n",
        "  \n",
        "I believe this also makes the architecture very sensitive to randomness of the initial values. In my experiments for several archetectures, it can be seen that in a range of k that was doing fine before, it suddenly jumps to 80+% error, but if reran it went down to something more expected. \n",
        "\n",
        "### CNN w/... + Batch Normalizations\n",
        "- This architecture actually didn't fail at the 20% error threshold consistently until around 220 layers but it was clearly struggling starting at 160. This is much higher than other architectures. It is particularly interesting that even with ELU activation which did noticeably worse previously, the batch normalization allowed a deeper depth than I had seen up until this point. Perhaps the normalization process allowed the gradients to stay within an reasonable range. \n",
        "\n",
        "### CNN w/... + Skip Connections\n",
        "  - This architecure made it higher than most of the others, maxing out somewhere around 160 layers. It was subject to the randomness I mentioned earlier. Given that the batch normalization also performed similarly, it is not clear if the skip connections helped any. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UHHtGGk6YSd"
      },
      "source": [
        "**<font color='red'> ---------------------------------------------------------------------- ANSWER (END) ----------------------------------------------------------------------\n",
        "</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHhjz1IT7rB4"
      },
      "source": [
        "### Interactions: Batch Norm and Initialization\n",
        "\n",
        "Intuitively, batch norm should make the model more robust to changes in the magnitude of the network's weights: informally, scaling up all the elements of a conv layer's filters by a factor of 10 would not affect the network's output as long as there is a batch norm layer following such convolution, as the normalization would undo the scaling.\n",
        "\n",
        "To check how this intuition translates to practical settings, you should change the original 'CNNtanh' model so that it incorporates batch norm layers (like you have done when modifying 'CNNelu' into 'CNNeluBN').\n",
        "\n",
        "The model below should adopt the naive initialization procedure of sampling from a Gaussian with a deviation of 0.05, not the more sophisticated one that you implemented previously"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8405idig8QGw"
      },
      "source": [
        "class CNNtanhBN_oldinit(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(CNNtanhBN_oldinit, self).__init__()\n",
        "\n",
        "        # write code here to instantiate layers\n",
        "        # for example, self.conv = nn.Conv2d(1, 4, 3, 1, 1)\n",
        "        # creates a conv layer with 1 input channel, 4 output\n",
        "        # channels, a 3x3 kernel, and stride=padding=1\n",
        "        k, lst, npt, otpt = (k//3)*3, [], 1, 4\n",
        "\n",
        "        for i in range(0,3): #create 3 stages\n",
        "\n",
        "          for _ in range(0, int(k/3)): #create k/3 convultion+tanh layers per stage, add to lst\n",
        "            lst.extend([nn.Conv2d(npt, otpt, 3, 1, 1), nn.BatchNorm2d(otpt), nn.Tanh()])\n",
        "            npt = otpt\n",
        "     \n",
        "\n",
        "          #at the end of stage i, double, channels, add pooling later\n",
        "          lst.append(nn.AvgPool2d(2, stride=2))\n",
        "          otpt = otpt *2\n",
        "\n",
        "        self.mdl = nn.Sequential(*lst)\n",
        "\n",
        "        sz = otpt//2 * 3* 3\n",
        "        self.fc=nn.Linear(sz, 10)\n",
        "\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                m.weight.data.normal_(0, 0.05)\n",
        "                m.bias.data.zero_()\n",
        "        \n",
        "    def forward(self, input):\n",
        "\n",
        "        # write code here to define how the output u is computed\n",
        "        # from the input and the model's layers\n",
        "        # for example, u = self.conv(input) defines u\n",
        "        # to be simply the output of self.conv given 'input'\n",
        "        u = self.mdl(input)\n",
        "        u = u.view(-1, np.prod(u.size()[1:4]))\n",
        "        u = self.fc(u)        \n",
        "        return u"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvZsUFsl-0-n"
      },
      "source": [
        "Repeat the procedure of finding the maximum number of layers such that the network is still trainable, this time with CNNeluBN_oldinit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYeWhIOpAnAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6224378d-35df-4185-ec85-6dfe73625de5"
      },
      "source": [
        "  k=0\n",
        "  for i in range(1,100):\n",
        "    k = k+3*(i//6+1)    \n",
        "    lr = .01  \n",
        "\n",
        "    print(\"\\nTraining Tanh CNN + BN + naive init with {} layers\".format(k))\n",
        "    model = CNNtanhBN_oldinit(k).cuda()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "    if test_errs >.2: \n",
        "      #try again\n",
        "      model = CNNtanhBN_oldinit(k).cuda()\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "      train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "      if test_errs >.2: break \n",
        "      \n",
        "#Try to find exact k by going back through with smaller steps\n",
        "  k =  k-3*(i//6+1)\n",
        "  print(f'\\nStarting back at k={k} and proceeding with smaller steps.')\n",
        "  for i in range(0,100):\n",
        "    k = k+3*(i//6+1)\n",
        "\n",
        "    print(\"\\nTraining Tanh CNN + BN + naive init with {} layers\".format(k))\n",
        "    model = CNNtanhBN_oldinit(k).cuda()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "    if test_errs >.2: \n",
        "      #try again\n",
        "      model = CNNtanhBN_oldinit(k).cuda()\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "      train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "      if test_errs >.2: break s"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Tanh CNN + BN + naive init with 3 layers\n",
            "Epoch 000/003, Train Error 15.77% || Test Error 5.23%\n",
            "Epoch 001/003, Train Error 9.33% || Test Error 5.27%\n",
            "Epoch 002/003, Train Error 4.71% || Test Error 3.85%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 6 layers\n",
            "Epoch 000/003, Train Error 12.37% || Test Error 6.56%\n",
            "Epoch 001/003, Train Error 10.71% || Test Error 3.96%\n",
            "Epoch 002/003, Train Error 3.85% || Test Error 2.98%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 9 layers\n",
            "Epoch 000/003, Train Error 10.10% || Test Error 3.58%\n",
            "Epoch 001/003, Train Error 8.77% || Test Error 3.12%\n",
            "Epoch 002/003, Train Error 2.79% || Test Error 2.17%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 12 layers\n",
            "Epoch 000/003, Train Error 10.33% || Test Error 3.04%\n",
            "Epoch 001/003, Train Error 9.14% || Test Error 3.73%\n",
            "Epoch 002/003, Train Error 3.35% || Test Error 2.75%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 15 layers\n",
            "Epoch 000/003, Train Error 10.29% || Test Error 2.95%\n",
            "Epoch 001/003, Train Error 15.68% || Test Error 7.07%\n",
            "Epoch 002/003, Train Error 4.86% || Test Error 4.23%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 21 layers\n",
            "Epoch 000/003, Train Error 12.38% || Test Error 4.14%\n",
            "Epoch 001/003, Train Error 18.52% || Test Error 6.45%\n",
            "Epoch 002/003, Train Error 5.28% || Test Error 4.03%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 27 layers\n",
            "Epoch 000/003, Train Error 10.74% || Test Error 3.31%\n",
            "Epoch 001/003, Train Error 2.90% || Test Error 6.23%\n",
            "Epoch 002/003, Train Error 2.10% || Test Error 1.74%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 33 layers\n",
            "Epoch 000/003, Train Error 13.14% || Test Error 9.52%\n",
            "Epoch 001/003, Train Error 9.55% || Test Error 4.37%\n",
            "Epoch 002/003, Train Error 3.75% || Test Error 3.17%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 39 layers\n",
            "Epoch 000/003, Train Error 16.30% || Test Error 5.96%\n",
            "Epoch 001/003, Train Error 4.59% || Test Error 3.35%\n",
            "Epoch 002/003, Train Error 2.94% || Test Error 2.71%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 45 layers\n",
            "Epoch 000/003, Train Error 19.85% || Test Error 5.20%\n",
            "Epoch 001/003, Train Error 5.50% || Test Error 3.51%\n",
            "Epoch 002/003, Train Error 3.47% || Test Error 3.45%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 51 layers\n",
            "Epoch 000/003, Train Error 18.92% || Test Error 5.78%\n",
            "Epoch 001/003, Train Error 5.69% || Test Error 3.29%\n",
            "Epoch 002/003, Train Error 3.23% || Test Error 3.04%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 60 layers\n",
            "Epoch 000/003, Train Error 28.91% || Test Error 9.38%\n",
            "Epoch 001/003, Train Error 6.25% || Test Error 4.66%\n",
            "Epoch 002/003, Train Error 3.74% || Test Error 3.38%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 69 layers\n",
            "Epoch 000/003, Train Error 24.78% || Test Error 10.78%\n",
            "Epoch 001/003, Train Error 8.76% || Test Error 4.36%\n",
            "Epoch 002/003, Train Error 4.74% || Test Error 4.29%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 78 layers\n",
            "Epoch 000/003, Train Error 31.22% || Test Error 13.55%\n",
            "Epoch 001/003, Train Error 12.59% || Test Error 9.37%\n",
            "Epoch 002/003, Train Error 8.39% || Test Error 10.34%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 87 layers\n",
            "Epoch 000/003, Train Error 39.43% || Test Error 56.48%\n",
            "Epoch 001/003, Train Error 27.06% || Test Error 14.32%\n",
            "Epoch 002/003, Train Error 14.83% || Test Error 13.51%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 96 layers\n",
            "Epoch 000/003, Train Error 45.40% || Test Error 24.72%\n",
            "Epoch 001/003, Train Error 21.19% || Test Error 15.03%\n",
            "Epoch 002/003, Train Error 13.21% || Test Error 11.31%\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 105 layers\n",
            "Epoch 000/003, Train Error 89.49% || Test Error 88.65%\n",
            "Epoch 001/003, Train Error 88.83% || Test Error 88.65%\n",
            "Epoch 002/003, Train Error 88.76% || Test Error 88.65%\n",
            "Epoch 000/003, Train Error 89.27% || Test Error 88.65%\n",
            "Epoch 001/003, Train Error 89.10% || Test Error 89.72%\n",
            "Epoch 002/003, Train Error 88.88% || Test Error 88.65%\n",
            "\n",
            "Starting back at k=96 and proceeding with smaller steps.\n",
            "\n",
            "Training Tanh CNN + BN + naive init with 99 layers\n",
            "Epoch 000/003, Train Error 83.86% || Test Error 75.71%\n",
            "Epoch 001/003, Train Error 82.67% || Test Error 74.67%\n",
            "Epoch 002/003, Train Error 70.68% || Test Error 64.84%\n",
            "Epoch 000/003, Train Error 67.49% || Test Error 50.96%\n",
            "Epoch 001/003, Train Error 85.29% || Test Error 90.18%\n",
            "Epoch 002/003, Train Error 89.53% || Test Error 88.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6m_C2V--8EI"
      },
      "source": [
        "**<font color='blue'>\n",
        "    Compare CNNtanh (model with naive initialization and no batch norm), CNNtanh_newinit (model with better initialization and no batch norm), and CNNtanhBN_oldinit (model with naive initialization and batch norm), in terms of how deep each could be while being trainable, and discuss your thoughts one how batch norm interacts with the way parameters are initialized.\n",
        "</font>**\n",
        "\n",
        "**<font color='red'> --------------------------------------------------------------------- ANSWER (BEGIN) ---------------------------------------------------------------------\n",
        "</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VNJUHbzwJ1-"
      },
      "source": [
        "CNNtanh only made it to 12 layers. CNNtanh_newinit to 102, and CNNtanhBN_oldinit to around 100. It seem that even with a random initialization the batch normalization improves the architecture greatly. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l428K7CT-9mp"
      },
      "source": [
        "**<font color='red'> ---------------------------------------------------------------------- ANSWER (END) ----------------------------------------------------------------------\n",
        "</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkrAaQgIBnQt"
      },
      "source": [
        "### Interactions: Batch Norm and Residual Connections\n",
        "\n",
        "Lastly, implement and train a CNN with residual connections but without batch normalization layers -- the goal here is to check how residuals interact with normalization.\n",
        "\n",
        "The model below should be exactly like ResNet, except that it should not have batch norm layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK05o-N4B3kG"
      },
      "source": [
        "class ResNet_noBN(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(ResNet_noBN, self).__init__()\n",
        "\n",
        "        # write code here to instantiate layers\n",
        "        # for example, self.conv = nn.Conv2d(1, 4, 3, 1, 1)\n",
        "        # creates a conv layer with 1 input channel, 4 output\n",
        "        # channels, a 3x3 kernel, and stride=padding=1\n",
        "\n",
        "        k, npt, otpt = (k//3)*3, 1, 4\n",
        "        lst = nn.ModuleList()  \n",
        "\n",
        "\n",
        "        for i in range(0,3): #create 3 stages\n",
        "          for _ in range(0, int(k/3)): #create k/3 convultion blocks per stage, add to lst\n",
        "            lst.extend([nn.Conv2d(npt, otpt, 3, 1, 1), nn.ELU()]) #be cautious with untested code\n",
        "            npt = otpt\n",
        "     \n",
        "\n",
        "          #at the end of stage i, double, channels, add pooling layer\n",
        "          lst.append(nn.AvgPool2d(2, stride=2))\n",
        "          otpt = otpt *2\n",
        "\n",
        "        self.mdl = lst\n",
        "\n",
        "        sz = otpt//2 * 3* 3\n",
        "        self.fc=nn.Linear(sz, 10)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # insert code to compute sigma\n",
        "                sigma = math.sqrt(1/(9*m.out_channels))\n",
        "                m.weight.data.normal_(0, sigma)\n",
        "                m.bias.data.zero_()\n",
        "        \n",
        "        \n",
        "    def forward(self, input):\n",
        "        \n",
        "        # write code here to define how the output u is computed\n",
        "        # from the input and the model's layers\n",
        "        # for example, u = self.conv(input) defines u\n",
        "        # to be simply the output of self.conv given 'input'\n",
        "        u = input\n",
        "\n",
        "        #do main part of model\n",
        "        for layer in self.mdl:\n",
        "          if isinstance(layer, nn.Conv2d): \n",
        "            u_block = u #save input when first encounter a new block\n",
        "            skip = layer.in_channels == layer.out_channels\n",
        "          if isinstance(layer, nn.ELU) and skip: u = layer(u)+u_block #when in == out channels and is ELU, do skip\n",
        "          else: u = layer(u)\n",
        "\n",
        "        #do fully connected  \n",
        "        u = u.view(-1, np.prod(u.size()[1:4]))\n",
        "        u = self.fc(u)\n",
        "        return u"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQLzjaz0CJFk"
      },
      "source": [
        "Repeat the procedure of finding the maximum number of layers such that the network is still trainable, this time with ResNet_noBN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_edbTtyCODr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452f5e9f-a7f2-4ccf-8911-97678aa3a3ce"
      },
      "source": [
        "  k=0\n",
        "  for i in range(1,100):\n",
        "    k = k+3*(i//6+1)    \n",
        "    lr = .01  \n",
        "\n",
        "    print(\"\\nTraining ResNet w/o BN with {} layers\".format(k))\n",
        "    model = ResNet_noBN(k).cuda()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "    if test_errs >.2: \n",
        "      #try again\n",
        "      model = ResNet_noBN(k).cuda()\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "      train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "      if test_errs >.2: break \n",
        "      \n",
        "#Try to find exact k by going back through with smaller steps\n",
        "  k =  k-3*(i//6+1)\n",
        "  print(f'\\nStarting back at k={k} and proceeding with smaller steps.')\n",
        "  for i in range(0,100):\n",
        "    k = k+3*(i//6+1)\n",
        "\n",
        "    print(\"\\nTraining ResNet w/o BN with {} layers\".format(k))\n",
        "    model = ResNet_noBN(k).cuda()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "    if test_errs >.2: \n",
        "      #try again\n",
        "      model = ResNet_noBN(k).cuda()\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "      train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)\n",
        "      if test_errs >.2: break \n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training ResNet w/o BN with 3 layers\n",
            "Epoch 000/003, Train Error 43.90% || Test Error 12.81%\n",
            "Epoch 001/003, Train Error 8.96% || Test Error 6.31%\n",
            "Epoch 002/003, Train Error 5.80% || Test Error 4.98%\n",
            "\n",
            "Training ResNet w/o BN with 6 layers\n",
            "Epoch 000/003, Train Error 21.69% || Test Error 5.43%\n",
            "Epoch 001/003, Train Error 4.13% || Test Error 3.09%\n",
            "Epoch 002/003, Train Error 2.89% || Test Error 2.14%\n",
            "\n",
            "Training ResNet w/o BN with 9 layers\n",
            "Epoch 000/003, Train Error 12.21% || Test Error 3.26%\n",
            "Epoch 001/003, Train Error 3.11% || Test Error 2.05%\n",
            "Epoch 002/003, Train Error 2.20% || Test Error 1.91%\n",
            "\n",
            "Training ResNet w/o BN with 12 layers\n",
            "Epoch 000/003, Train Error 11.60% || Test Error 4.32%\n",
            "Epoch 001/003, Train Error 2.51% || Test Error 1.94%\n",
            "Epoch 002/003, Train Error 1.83% || Test Error 1.43%\n",
            "\n",
            "Training ResNet w/o BN with 15 layers\n",
            "Epoch 000/003, Train Error 11.10% || Test Error 2.35%\n",
            "Epoch 001/003, Train Error 2.23% || Test Error 1.97%\n",
            "Epoch 002/003, Train Error 1.63% || Test Error 1.56%\n",
            "\n",
            "Training ResNet w/o BN with 21 layers\n",
            "Epoch 000/003, Train Error 90.14% || Test Error 90.20%\n",
            "Epoch 001/003, Train Error 90.13% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 90.13% || Test Error 90.20%\n",
            "Epoch 000/003, Train Error 90.12% || Test Error 90.20%\n",
            "Epoch 001/003, Train Error 90.13% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 90.13% || Test Error 90.20%\n",
            "\n",
            "Starting back at k=15 and proceeding with smaller steps.\n",
            "\n",
            "Training ResNet w/o BN with 18 layers\n",
            "Epoch 000/003, Train Error 90.00% || Test Error 90.20%\n",
            "Epoch 001/003, Train Error 90.13% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 90.13% || Test Error 90.20%\n",
            "Epoch 000/003, Train Error 90.08% || Test Error 90.20%\n",
            "Epoch 001/003, Train Error 90.13% || Test Error 90.20%\n",
            "Epoch 002/003, Train Error 90.13% || Test Error 90.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV_vayTUCMJc"
      },
      "source": [
        "**<font color='blue'>\n",
        "    Compare ResNet and ResNet_noBN in terms of how deep each could be while being trainable, and discuss your thoughts one how batch norm interacts with residual connections.\n",
        "</font>**\n",
        "\n",
        "**<font color='red'> --------------------------------------------------------------------- ANSWER (BEGIN) ---------------------------------------------------------------------\n",
        "</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJiNB0crv9IH"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLremM7AW66L"
      },
      "source": [
        "ResNet_noBN did very poorly maxing at around 15 layers compared to Resnet at around 160. I think that batch norming is making all the difference and something about the architecure is not allowing the residual connections to improve very much on our base architecture. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "038qemzGW62W"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdqTHhOJCPVu"
      },
      "source": [
        "**<font color='red'> ---------------------------------------------------------------------- ANSWER (END) ----------------------------------------------------------------------\n",
        "</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjZF-f5PCgZ9"
      },
      "source": [
        "### (Optional) Multiple Loss Heads\n",
        "\n",
        "In this optional section, your goal is to incorporate the idea of having multiple loss heads throughout the network, distributed across its depth.\n",
        "\n",
        "For the CNNelu_multihead model below, you should take the CNNelu model that you implemented previously and add two additional classification heads, connected to the outputs of stages 1 and 2.\n",
        "\n",
        "More specifically, the outputs of stages 1 and 2, with shapes 4x14x14 and 8x7x7, should be connected to new fully-connected layers that map them to a 10-dimensional vector (logits for the 10 MNIST classes). The network should output three logit vectors (the original one at the end of the network plus the two new ones) instead of just one, and the loss should be computed as the average of the cross entropies between the true target and each of the three predictions.\n",
        "\n",
        "Note that you will likely have to change the implementation of train_epoch() and test() to accomodate the fact that this model will output three logit vectors instead of one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjq7whPVDR--"
      },
      "source": [
        "class CNNelu_multihead(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(CNNelu_multihead, self).__init__()\n",
        "\n",
        "        # write code here to instantiate layers\n",
        "        # for example, self.conv = nn.Conv2d(1, 4, 3, 1, 1)\n",
        "        # creates a conv layer with 1 input channel, 4 output\n",
        "        # channels, a 3x3 kernel, and stride=padding=1\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # insert code to compute sigma\n",
        "                sigma = \n",
        "                m.weight.data.normal_(0, sigma)\n",
        "                m.bias.data.zero_()\n",
        "        \n",
        "    def forward(self, input):\n",
        "        # write code here to define how the output u is computed\n",
        "        # from the input and the model's layers\n",
        "        # for example, u = self.conv(input) defines u\n",
        "        # to be simply the output of self.conv given 'input'\n",
        "\n",
        "        return u1, u2, u3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmTspBA6Fnfr"
      },
      "source": [
        "Repeat the procedure of finding the maximum number of layers such that the network is still trainable, this time with CNNelu_multihead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovdjbI8jJttc"
      },
      "source": [
        "k = \n",
        "lr = \n",
        "\n",
        "print(\"\\nTraining ELU CNN + multiloss with {} layers\".format(k))\n",
        "model = CNNelu_multihead(k).cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "train_errs, test_errs = train(3, model, criterion, optimizer, train_loader, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1x_FYzEFsoj"
      },
      "source": [
        "**<font color='blue'>\n",
        "    Did the adoption of multiple loss heads help train deeper models? How did it compare to the adoption of batch normalization, in terms of how deeper each of the two approaches enabled the network to be while staying trainable?\n",
        "</font>**\n",
        "\n",
        "**<font color='red'> --------------------------------------------------------------------- ANSWER (BEGIN) ---------------------------------------------------------------------\n",
        "</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djfPeR3xFt9U"
      },
      "source": [
        "**<font color='red'> ---------------------------------------------------------------------- ANSWER (END) ----------------------------------------------------------------------\n",
        "</font>**"
      ]
    }
  ]
}